<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Positive Predictive Value · MLMetrics.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/style.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../index.html"><img class="logo" src="../../assets/logo.png" alt="MLMetrics.jl logo"/></a><h1>MLMetrics.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><a class="toctext" href="../../gettingstarted/">Getting Started</a></li><li><a class="toctext" href="../../classification/">Classification Metrics</a><ul><li class="current"><a class="toctext" href>Positive Predictive Value</a><ul class="internal"></ul></li></ul></li><li><a class="toctext" href="../../LICENSE/">LICENSE</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="../../classification/">Classification Metrics</a></li><li><a href>Positive Predictive Value</a></li></ul><a class="edit-page" href="https://github.com/JuliaML/MLMetrics.jl/blob/master/docs/src/fractions/positive_predictive_value.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Positive Predictive Value</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Positive-Predictive-Value-1" href="#Positive-Predictive-Value-1">Positive Predictive Value</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLMetrics.positive_predictive_value" href="#MLMetrics.positive_predictive_value"><code>MLMetrics.positive_predictive_value</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">positive_predictive_value(targets, outputs, [encoding], [avgmode = :none]) -&gt; Union{Float64, Dict}</code></pre><p>Return the fraction of positive predicted outcomes in <code>outputs</code> that are true positives according to the correspondig <code>targets</code>. This is also known as &quot;precision&quot; (alias <code>precision_score</code>). Which value(s) denote &quot;positive&quot; or &quot;negative&quot; depends on the given (or inferred) <code>encoding</code>.</p><p>If <code>encoding</code> is omitted, the appropriate <code>MLLabelUtils.LabelEncoding</code> will be inferred from the types and/or values of <code>targets</code> and <code>outputs</code>. Note that omitting the <code>encoding</code> can cause performance penalties, which may include a lack of return-type inference.</p><p>The return value of the function depends on the number of labels in the given <code>encoding</code> and on the specified <code>avgmode</code>. In case an <code>avgmode</code> other than <code>:none</code> is specified, or the <code>encoding</code> is binary (i.e. it has exactly 2 labels), a single number is returned. Otherwise, the function will compute a separate result for each individual label, where that label is treated as &quot;positive&quot; and the other labels are treated as &quot;negative&quot;. These results are then returned as a single dictionary with an entry for each label.</p><p><strong>Arguments</strong></p><ul><li><p><code>targets::AbstractArray</code>: The array of ground truths <span>$\mathbf{y}$</span>.</p></li><li><p><code>outputs::AbstractArray</code>: The array of predicted outputs <span>$\mathbf{\hat{y}}$</span>.</p></li><li><p><code>encoding</code>: Optional. Specifies the possible values in <code>targets</code> and <code>outputs</code> and their interpretation (e.g. what constitutes as a positive or negative label, how many labels exist, etc). It can either be an object from the namespace <code>LabelEnc</code>, or a vector of labels.</p></li><li><p><code>avgmode</code>: Optional keyword argument. Specifies if and how class-specific results should be aggregated. This is mainly useful if there are more than two classes. Typical values are <code>:none</code> (default), <code>:micro</code> for micro averaging, or <code>:macro</code> for macro averaging. It is also possible to specify <code>avgmode</code> as a type-stable positional argument using an object from the <code>AvgMode</code> namespace.</p></li></ul><p><strong>See also</strong></p><p><a href="../../counts/true_positives/#MLMetrics.true_positives"><code>true_positives</code></a>, <a href="../../counts/predicted_positive/#MLMetrics.predicted_positive"><code>predicted_positive</code></a>, <a href="../true_positive_rate/#MLMetrics.true_positive_rate"><code>true_positive_rate</code></a> (aka &quot;recall&quot; or &quot;sensitivity&quot;), <a href="../f_score/#MLMetrics.f_score"><code>f_score</code></a></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; precision_score([0,1,1,0,1], [1,1,1,0,1])
0.75

julia&gt; precision_score([-1,1,1,-1,1], [1,1,1,-1,1])
0.75

julia&gt; precision_score([:a,:b,:a,:c,:c], [:a,:c,:b,:c,:c], LabelEnc.OneVsRest(:c))
0.6666666666666666

julia&gt; precision_score([:a,:b,:a,:c,:c], [:a,:c,:b,:c,:c]) # avgmode=:none
Dict{Symbol,Float64} with 3 entries:
  :a =&gt; 1.0
  :b =&gt; 0.0
  :c =&gt; 0.666667

julia&gt; precision_score([:a,:b,:a,:c,:c], [:a,:c,:b,:c,:c], avgmode=:micro)
0.6

julia&gt; precision_score([:a,:b,:a,:c,:c], [:a,:c,:b,:c,:c], avgmode=:macro)
0.5555555555555555</code></pre></div></div></section><footer><hr/><a class="previous" href="../positive_likelihood_ratio/"><span class="direction">Previous</span><span class="title">Positive Likelihood Ratio</span></a><a class="next" href="../prevalence/"><span class="direction">Next</span><span class="title">Prevalence</span></a></footer></article></body></html>
