<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>True Positives · MLMetrics.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="../../assets/style.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../../index.html"><img class="logo" src="../../assets/logo.png" alt="MLMetrics.jl logo"/></a><h1>MLMetrics.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><a class="toctext" href="../../gettingstarted/">Getting Started</a></li><li><a class="toctext" href="../../classification/">Classification Metrics</a><ul><li class="current"><a class="toctext" href>True Positives</a><ul class="internal"></ul></li></ul></li><li><a class="toctext" href="../../LICENSE/">LICENSE</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="../../classification/">Classification Metrics</a></li><li><a href>True Positives</a></li></ul><a class="edit-page" href="https://github.com/JuliaML/MLMetrics.jl/blob/master/docs/src/counts/true_positives.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>True Positives</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="True-Positives-1" href="#True-Positives-1">True Positives</a></h1><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MLMetrics.true_positives" href="#MLMetrics.true_positives"><code>MLMetrics.true_positives</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">true_positives(targets, outputs, [encoding]) -&gt; Union{Int, Dict}</code></pre><p>Count how many positive predicted outcomes in <code>outputs</code> are also marked as positive outcomes in <code>targets</code>. Which value denotes &quot;positive&quot; depends on the given (or inferred) <code>encoding</code>. Typically both parameters are arrays of some form, (e.g. vectors or row-vectors), but its also possible to provide a single obseration as &quot;scalar&quot; value.</p><p>The return value of the function depends on the number of labels in the given <code>encoding</code>. In case the <code>encoding</code> is binary (i.e. it has exactly 2 labels), a single integer value is returned. Otherwise, the function will compute a separate result for each individual label, where that label is treated as &quot;positive&quot; and the other labels are treated as &quot;negative&quot;. These results are then returned as a single dictionary with an entry for each label.</p><p>If <code>encoding</code> is omitted, the appropriate <code>MLLabelUtils.LabelEncoding</code> will be inferred from the types and/or values of <code>targets</code> and <code>outputs</code>. Note that omitting the <code>encoding</code> can cause performance penalties, which may include a lack of return-type inference.</p><p><strong>Arguments</strong></p><ul><li><p><code>targets</code>: Either an array of multiple ground truths <span>$\mathbf{y}$</span>, or a single ground truth <span>$y$</span>.</p></li><li><p><code>outputs</code>: Either an array of multiple predicted outputs <span>$\mathbf{\hat{y}}$</span>, or a single prediction <span>$\hat{y}$</span>.</p></li><li><p><code>encoding</code>: Optional. Specifies the possible values in <code>targets</code> and <code>outputs</code> and their interpretation (e.g. what constitutes as a positive or negative label, how many labels exist, etc). It can either be an object from the namespace <code>LabelEnc</code>, or a vector of labels.</p></li></ul><p><strong>See also</strong></p><p><a href="../predicted_positive/#MLMetrics.predicted_positive"><code>predicted_positive</code></a>, <a href="../condition_positive/#MLMetrics.condition_positive"><code>condition_positive</code></a>, <a href="../../fractions/true_positive_rate/#MLMetrics.true_positive_rate"><code>true_positive_rate</code></a></p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; true_positives(1, 1, LabelEnc.ZeroOne()) # single observation
1

julia&gt; true_positives([1,0,1,1,0], [1,1,1,0,0]) # multiple observations
2

julia&gt; true_positives([:a,:a,:b,:b,:c,:c], [:a,:b,:b,:b,:a,:a]) # multi-class
Dict{Symbol,Int64} with 3 entries:
  :a =&gt; 1
  :b =&gt; 2
  :c =&gt; 0</code></pre></div></div></section><footer><hr/><a class="previous" href="../true_negatives/"><span class="direction">Previous</span><span class="title">True Negatives</span></a><a class="next" href="../../fractions/accuracy/"><span class="direction">Next</span><span class="title">Accuracy</span></a></footer></article></body></html>
